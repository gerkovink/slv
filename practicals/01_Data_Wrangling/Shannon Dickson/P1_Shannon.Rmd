---
title: "SLV Practical 1: Data Wrangling"
author: "Shannon Dickson"
date: "`r format(Sys.Date(), '%B %d %Y')`"
output: 
   bookdown::html_document2:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: false
    theme: paper
    
---
<style type="text/css">
  
body{ /* Normal  */
  font-size: 12px;
  }
td {  /* Table  */
  font-size: 12px;
}
h1.title {
  font-size: 18px;
  color: DarkBlue;
}
h1 { /* Header 1 */
  font-size: 18px;
}
h2 { /* Header 2 */
  font-size: 18px;
}
h3 { /* Header 3 */
  font-size: 18px;
}
code.r{ /* Code block */
  font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
  font-size: 14px;
}
</style>

---

```{r setup, echo = FALSE}
library(knitr)
knitr::opts_chunk$set(include = TRUE, 
                      echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE)
```

# Preparation

Packages required for the tutorial:

```{r}
library(ISLR)
library(tidyverse)
library(haven)
library(readxl)
```

# Data types

**1. Inspecting the `class()` of the following:**

* Object 1 is integer
* Object 2 is integer
* Object 3 is character
* Object 4 is numeric
* Object 5 is character
* Object 6 is factor
* Object 7 is character

```{r}
object_1 <- 1:5
object_2 <- 1L:5L
object_3 <- "-123.456"
object_4 <- as.numeric(object_2)
object_5 <- letters[object_1]
object_6 <- as.factor(rep(object_5, 2))
object_7 <- c(1, 2, 3, "4", "5", "6")
```


**2. Convert `object_7` back to a vector of numbers using the `as.numeric()` function.**

```{r}
object_7 <- as.numeric(object_7)
```

# Lists and data frames

**3. Make a list called `objects` containing object 1 to 7 using the `list()` function.**

```{r}
objects <- list(c(object_1,
                  object_2,
                  object_3,
                  object_4,
                  object_5,
                  object_6,
                  object_7))
```

**4. Make a data frame out of `object_1`, `object_2`, and `object_5` using the `data.frame()` function**

```{r}
df <- data.frame(object_1, object_2, object_5)
```

**5. Useful functions for determining the size of a data frame are `ncol()` and `nrow()`. Try them out!**

```{r}
ncol(df)
nrow(df)
```

# Loading, viewing, and summarising data

**6. Use the function `read_csv()` to import the file "googleplaystore.csv" and store it in a variable called `apps`**

```{r}
apps <- read_csv("googleplaystore.csv")
```

**7. Did any column get a variable type you did not expect?**

Some of the character variables would be better stored as factors with levels. 

```{r}
str(apps)
```

**8. Use the function `head()` to look at the first few rows of the apps dataset**

```{r}
head(apps)
```
**9. Repeat steps 5, 6, and 7 but now for “data/students.xlsx” (NB: You’ll need a function from the package readxl). Also try out the function tail() and View() (with a capital V).**

```{r}
students <- read_xlsx("students.xlsx")

ncol(students)
nrow(students)

str(students)

head(students)
```
**10. Create a summary of the three columns in the students dataset using the summary() function. What is the range of the grades achieved by the students?**

The grade range is 4.84 to 9.29, with an average grade of 6.99. 

```{r}
summary(students)
```

# Data transformation with dplyr verbs 

## Filter

**11. Look at the help pages for filter() (especially the examples) and show the students with a grade lower than 5.5.**

There are 3 students with a grade lower than 5.5

```{r}
students %>% 
  filter(grade < 5.5)
```

**12. Show only the students with a grade higher than 8 from programme A**

There are 5 students with a grade higher than 8 from programme A. 

```{r}
students %>% 
  filter(grade > 8 & programme == "A")
```

## Arrange

**13. Sort the students dataset such that the students from programme A are on top of the data frame and within the programmes the highest grades come first.**

```{r}
students %>% arrange(programme, desc(grade))
```
## Select

**14. Show only the student_number and programme columns from the students dataset**

```{r}
students %>% 
  select(student_number, programme)
```
## Mutate

```{r}
students %>% 
  mutate(pass = grade > 5.5)

```

**15. Use mutate() and recode() to change the codes in the programme column of the students dataset to their names. Store the result in a variable called students_recoded**

```{r}
students_recoded <- students %>% 
  mutate(programme = recode(programme,
                            "A" = "Science",
                            "B" = "Social Scoence"
  ))
```

# Data processing pipelines

```{r}
students_dataset <-
  read_xlsx("students.xlsx") %>% 
  mutate(prog = recode(programme, "A" = "Science", "B" = "Social Science")) %>% 
  filter(grade > 5.5) %>% 
  arrange(programme, -grade) %>% 
  select(student_number, prog, grade)
students_dataset
```
**16. Create a data processing pipeline that (a) loads the apps dataset, (b) parses the number of installs as ‘Downloads’ variable using mutate and parse_number(), (c) shows only apps with more than 500 000 000 downloads, (d) orders them by rating (best on top), and (e) shows only the relevant columns (you can choose which are relevant, but select at least the Rating and Category variables). Save the result under the name popular_apps.**

```{r}
popular_apps <-
  read_csv("googleplaystore.csv") %>% 
  mutate(Downloads = parse_number(Installs)) %>% 
  filter(Downloads > 5e8) %>% 
  arrange(-Rating) %>% 
  select(App, Rating, Reviews, Downloads, Category) %>% 
  distinct(App, .keep_all = TRUE)
popular_apps
```

## Grouping and summarisation

```{r}
students_dataset %>% 
  summarise(
    mean = mean(grade), 
    variance = var(grade), 
    min = min(grade), 
    max = max(grade)
  )
```
**17. Show the median, minimum, and maximum for the popular apps dataset you made in the previous assignment.**

```{r}
popular_apps %>% 
  summarise(
    med = median(Rating),
    min = min(Rating), 
    max = max(Rating)
  )
```
**Median Absolute Deviation (MAD) function**

```{r}
mad <- function(x) {
  median(abs(x - median(x)))
}

students_dataset %>%
  summarise(mad = mad(grade))
```

**18. Add the median absolute deviation to the summaries you made before**

```{r}
popular_apps %>% 
  summarise(
    med = median(Rating),
    min = min(Rating), 
    max = max(Rating),
    mad = mad(Rating)
  )
```

```{r}
students_dataset %>% 
  group_by(prog) %>% 
  summarise(
    mean = mean(grade), 
    variance = var(grade), 
    min = min(grade), 
    max = max(grade)
  )
```

**19. Create a grouped summary of the ratings per category in the popular apps dataset.**

```{r}
popular_apps %>% 
  group_by(Category) %>% 
  summarise(
    min = min(Rating),
    med = median(Rating),
    mean = mean(Rating),
    max = max(Rating),
    mad = mad(Rating)
  )
```


# Final exercise

**20. Create an interesting summary based on the Google play store apps dataset. An example could be “do games get higher ratings than communication apps?”**

*Do games get higher average ratings than communication apps?*

```{r}
popular_apps %>% 
  select(App, Category, Rating) %>% 
  filter(Category == "GAME" | Category == "COMMUNICATION") %>% 
  group_by(Category) %>% 
  summarise(mean = mean(Rating, na.rm = T))
```

